{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# International College of Economics and Finance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Econometrics. Class 04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Inspired by [Forecasting: Principles and Practice](https://otexts.com/fpp2/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class outline\n",
    "- Let's find the best in terms of prediction ability model for SP500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:09:04.046405Z",
     "start_time": "2020-10-09T23:09:02.965Z"
    }
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# For those who has a problem like: package ‘package_name’ is not available (for R version x.x.x)\n",
    "# install.packages('package_name', dependencies=TRUE, repos='http://cran.rstudio.com/')\n",
    "\n",
    "library(quantmod)\n",
    "library(multDM)\n",
    "library(forecast) #I highly recommend to visit the link above. It explains basics of forecasting and time-series modeling in R\n",
    "\n",
    "# For those who have operational system in Russian but wants it in English\n",
    "Sys.setlocale(\"LC_TIME\", \"C\")\n",
    "format(Sys.Date(), format = \"%Y-%b-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:09:05.480227Z",
     "start_time": "2020-10-09T23:09:02.996Z"
    }
   },
   "outputs": [],
   "source": [
    "sp <- getSymbols(\"^GSPC\", scr = \"yahoo\", auto.assign = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:09:05.502263Z",
     "start_time": "2020-10-09T23:09:02.999Z"
    }
   },
   "outputs": [],
   "source": [
    "sp.price <- sp$GSPC.Adjusted\n",
    "sp.ret <- diff(log(sp.price))[-1] * 100\n",
    "names(sp.ret) <- c('S&P500 log returns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models and forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's revisit our previous class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:09:05.526270Z",
     "start_time": "2020-10-09T23:09:03.059Z"
    }
   },
   "outputs": [],
   "source": [
    "N <- length(sp.ret) # let's have a variable with the size\\length of our data\n",
    "N_OOS <- round(x = 0.3 * N, digits = 0) # Usually, 25%-30% of data are used for the prediction period\n",
    "N_sample <- N - N_OOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:09:07.109226Z",
     "start_time": "2020-10-09T23:09:03.061Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train <- vector(mode = 'logical', length = N_sample)\n",
    "y_pred_mean <- vector(mode = 'logical', length = N_OOS)\n",
    "y_pred_ar <- vector(mode = 'logical', length = N_OOS)\n",
    "y_true <- sp.ret[(N_sample + 1):N]\n",
    "\n",
    "for (i in 1:N_OOS){\n",
    "    y_train <- sp.ret[i:(N_sample + i - 1)] #It is a good practice to store your in-sample data\n",
    "    y_pred_mean[i] <- mean(y_train) # Because then you can just call the function on it\n",
    "    ar <- lm(y_train ~ lag(y_train))\n",
    "    y_pred_ar[i] <- ar$coefficients[1] + ar$coefficients[2] * y_train[N_sample]\n",
    "}\n",
    "\n",
    "y_pred_mean <- as.xts(x = y_pred_mean, order.by = index(y_true))\n",
    "y_pred_ar <- as.xts(x = y_pred_ar, order.by = index(y_true))\n",
    "\n",
    "mse_mean <- mean((y_true - y_pred_mean)^2)\n",
    "mse_ar <- mean((y_true - y_pred_ar)^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:09:19.046832Z",
     "start_time": "2020-10-09T23:09:18.899Z"
    }
   },
   "outputs": [],
   "source": [
    "par(xpd = T)\n",
    "plot(x = cbind(y_true, y_pred_mean, y_pred_ar), \n",
    "     main = 'Returns and predictions', \n",
    "     y = index(y_true), \n",
    "     col = c('black', 'red', 'blue'),\n",
    "     lwd = c(1, 2, 2))\n",
    "legend('bottomleft', \n",
    "       legend = c('Returns', 'Mean model predictions', 'AR(1) model predictions'), \n",
    "       col = c('black', 'red', 'blue'),\n",
    "       lty = c(1, 1, 1),\n",
    "       inset = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:09:20.173146Z",
     "start_time": "2020-10-09T23:09:20.150Z"
    }
   },
   "outputs": [],
   "source": [
    "mse_mean; mse_ar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Well, we see that AR(1) model has lower MSE\n",
    "- But we want to see if its forecasts are statistically better than those of mean model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DM test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So, I hope that you remember the procedure\n",
    "    - Make two sequence of predictions $\\hat{y_1} \\text{ and } \\hat{y_2}$\n",
    "    - Calculate the loss function (in our case it is a squared loss): $L(e_1) = (y - \\hat{y_1})^2; L(e_2) = (y - \\hat{y_2})^2$\n",
    "    - Calculate the difference between them: $d = L(e_1) - L(e_2)$\n",
    "    - If forecasts are the same: $H_0: E(d) = 0$\n",
    "    - If not: $H_1: E(d) \\ne 0$\n",
    "    - Calculate good old t-stat: $t = \\frac{\\frac{1}{T}\\sum_1^T d}{\\sqrt{\\hat{\\sigma_d}/T}}=DM$\n",
    "    - For estimation of $\\hat{\\sigma_d}$ use `HAC` estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:09:21.801142Z",
     "start_time": "2020-10-09T23:09:21.779Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's go\n",
    "L.mean_model = (y_true - y_pred_mean)^2\n",
    "L.ar = (y_true - y_pred_ar)^2\n",
    "\n",
    "d = L.mean_model - L.ar\n",
    "\n",
    "d.mean = mean(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As for calculation of HAC estimator I will use (Newey-West, 1987)\n",
    "- Also, check this [chapter](https://www.econometrics-with-r.org/15-4-hac-standard-errors.html)\n",
    "- (Newey-West, 1987) HAC estimator\n",
    "    - So, if our $d$ is actually not serially correlated, then: $V(\\bar{d}) = V(\\frac{1}{T}\\sum_{t=1}^{T}d_t) = \\frac{1}{T^2}\\sum_{t=1}^{T}V(d_t) = \\frac{1}{T}V(d_t)$. In other words it is just an unbiased variance estimator: $\\hat{V}(d_t) = \\frac{1}{T-1}\\sum_{t=1}^{T}(d_t - \\bar{d})^2$\n",
    "    - Of course, we cannot say that. Hence: $V(\\bar{d}) = V(\\frac{1}{T}\\sum_{t=1}^{T}d_t) = \\frac{1}{T^2}\\sum_{t=1}^{T}V(d_t) + \\frac{2}{T^2}\\sum_{t=1}^{T-1} \\sum_{k=t+1}^{T}cov(d_t, d_k) \\stackrel{why?}= \\frac{1}{T^2}\\sum_{t=1}^{T}V(d_t) + \\frac{2}{T^2}\\sum_{j=1}^{T-1} (T - j) cov(d_t, d_{t+j})$\n",
    "    - It is also a good practice to truncate the sum of autocovariances. In most cases it is suggested to use $m = T^{\\frac{1}{3}}$\n",
    "    - Hence, Newey-West estimator is: $\\frac{1}{T}\\hat{V(d_t)} + \\frac{2}{T}\\sum_{j=1}^{m} (1 - \\frac{j}{m+1}) \\hat{cov}(d_t, d_{t+j})$\n",
    "    - But we have some aces. This one (Diebold, F.X. and Mariano, R.S. (1995)). Authors say that the truncation lag should be $(h-1)$, where $h$ - h-step-ahead forecast. In our case, $h = 1$, meaning, that in 1-step-ahead forecast we can say that Newey-West estimator is $\\frac{1}{T}\\hat{V}(d_t) = \\frac{1}{T} \\cdot \\frac{1}{T-1}\\sum_{t=1}^{T}(d_t - \\bar{d})$\n",
    "    - Meaning that we need to use unbiased variance estimator divided by the number of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:09:22.765541Z",
     "start_time": "2020-10-09T23:09:22.748Z"
    }
   },
   "outputs": [],
   "source": [
    "d.var <- var(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:09:23.030576Z",
     "start_time": "2020-10-09T23:09:23.013Z"
    }
   },
   "outputs": [],
   "source": [
    "dm <- d.mean/sqrt(d.var/length(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:09:23.430387Z",
     "start_time": "2020-10-09T23:09:23.382Z"
    }
   },
   "outputs": [],
   "source": [
    "dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:09:23.634045Z",
     "start_time": "2020-10-09T23:09:23.612Z"
    }
   },
   "outputs": [],
   "source": [
    "2 * pnorm(q = -abs(dm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Harvey, Leybourne, and Newbold (1997) (HLN) suggest that improved small-sample properties can be obtained by:\n",
    "    - making a bias correction to the DM test statistic, and\n",
    "    - comparing the corrected statistic with a Student-t distribution with (T-1) degrees of freedom, rather than the standard normal.\n",
    "- The corrected statistic is obtained as:  \n",
    "$$\\sqrt{\\frac{T + 1 - 2h + h(h-1)}{T}}\\cdot DM \\sim t_{T-1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:09:24.059506Z",
     "start_time": "2020-10-09T23:09:24.039Z"
    }
   },
   "outputs": [],
   "source": [
    "T <- length(d)\n",
    "h <- 1\n",
    "k <- ((T + 1 - 2 * h + (h / T) * (h - 1)) / T) ^ (1 / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:09:24.248505Z",
     "start_time": "2020-10-09T23:09:24.230Z"
    }
   },
   "outputs": [],
   "source": [
    "hln <- dm*k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:09:24.473409Z",
     "start_time": "2020-10-09T23:09:24.451Z"
    }
   },
   "outputs": [],
   "source": [
    "2 * pt(-abs(hln), df = T - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:09:25.122338Z",
     "start_time": "2020-10-09T23:09:25.100Z"
    }
   },
   "outputs": [],
   "source": [
    "#checking ourselves\n",
    "dm.test(e1 = L.mean_model, e2 = L.ar, power = 1) #We have already squared our errors, that's why power = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:09:25.354338Z",
     "start_time": "2020-10-09T23:09:25.327Z"
    }
   },
   "outputs": [],
   "source": [
    "# A small difference is only because we used unbiased estimator of variance, while in the function a biased one is used\n",
    "biased_var <- function(x){\n",
    "    m <- mean(x)\n",
    "    result <- sum((x - m)^2)/length(x)\n",
    "    result\n",
    "}\n",
    "\n",
    "d.mean/sqrt(biased_var(d)/T)*k; 2*pt(q = -abs(d.mean/sqrt(biased_var(d)/T)*k), df = T - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple model comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I hope that you remember lecture\n",
    "- Anyway, a small reminder\n",
    "    - We have `k+1` models\n",
    "    - We are trying to test: $H_0: E[L(e^1_t)] = E[L(e^2_t)] = ... = E[L(e^{k+1}_t)]$\n",
    "    - Basically, we have: $H_0: E[{\\bf d_t}] = 0, \\text{ where } {\\bf d_t} = \\left( d_{1,t}, d_{2, t}, ... , d_{k, t} \\right), \\text{ and } d_{j, t} = L(e^j_t) - L(e^{j+1}_t), j = 1...k$\n",
    "    - Then, our statistic looks like: $T \\cdot {\\bf{\\bar{d}}}' \\cdot \\hat{\\Omega}^{-1} \\cdot {\\bf{\\bar{d}}} \\overset{a}{\\rightarrow} \\chi^2_k$\n",
    "- Ok, let's do it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First, we need another model as we have only two: mean model and AR(1) model\n",
    "- I decided to use MA(1) model for forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- library `forecast` has its own `Arima()` function that differs from built-in `arima()` function:  \n",
    ">If you want to choose the model yourself, use the `Arima()` function in R. There is another function `arima()` in R which also fits an ARIMA model. However, it does not allow for the constant c unless $d = 0$, and it does not return everything required for other functions in the `forecast` package to work. Finally, it does not allow the estimated model to be applied to new data (which is useful for checking forecast accuracy). Consequently, it is recommended that `Arima()` be used instead.\n",
    "\n",
    "[source](https://otexts.com/fpp2/arima-r.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I hope that you check the source above\n",
    "- To put it simple, you need only two functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:09:27.279430Z",
     "start_time": "2020-10-09T23:09:27.231Z"
    }
   },
   "outputs": [],
   "source": [
    "# First, is fitting the model\n",
    "test_model <- Arima(y = sp.ret, order = c(1, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:09:27.716086Z",
     "start_time": "2020-10-09T23:09:27.692Z"
    }
   },
   "outputs": [],
   "source": [
    "summary(test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:09:27.945503Z",
     "start_time": "2020-10-09T23:09:27.911Z"
    }
   },
   "outputs": [],
   "source": [
    "str(test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:09:28.111293Z",
     "start_time": "2020-10-09T23:09:28.087Z"
    }
   },
   "outputs": [],
   "source": [
    "# And the 1-step ahead forecasting from the model\n",
    "test_pred <- forecast(object = test_model, h = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:09:28.677096Z",
     "start_time": "2020-10-09T23:09:28.653Z"
    }
   },
   "outputs": [],
   "source": [
    "summary(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:09:28.900041Z",
     "start_time": "2020-10-09T23:09:28.862Z"
    }
   },
   "outputs": [],
   "source": [
    "str(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:09:29.063666Z",
     "start_time": "2020-10-09T23:09:29.041Z"
    }
   },
   "outputs": [],
   "source": [
    "# Probably, we want the point forecats value\n",
    "test_pred$mean[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:09:43.793278Z",
     "start_time": "2020-10-09T23:09:29.253Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now, let's get predictions for MA(1) model\n",
    "y_pred_ma <- # initialiaze a vector\n",
    "\n",
    "for (i in 1:N_OOS){\n",
    "    y_train <- # keep your train data\n",
    "    ma <- #fit the model on your train data\n",
    "    y_pred_ma[i] <- #make a forecast\n",
    "}\n",
    "\n",
    "y_pred_ma <- as.xts(y_pred_ma, order.by = index(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:10:35.170075Z",
     "start_time": "2020-10-09T23:10:34.999Z"
    }
   },
   "outputs": [],
   "source": [
    "par(xpd = T)\n",
    "plot(x = cbind(y_true, y_pred_mean, y_pred_ar, y_pred_ma), \n",
    "     main = 'Returns and predictions', \n",
    "     y = index(y_true), \n",
    "     col = c('black', 'red', 'blue', 'green'),\n",
    "     lwd = c(1, 2, 2, 2))\n",
    "legend('bottomleft', \n",
    "       legend = c('Returns', 'Mean model predictions', 'AR(1) model predictions', 'MA(1) model predictions'), \n",
    "       col = c('black', 'red', 'blue', 'green'),\n",
    "       lty = c(1, 1, 1, 1),\n",
    "       inset = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:10:36.646308Z",
     "start_time": "2020-10-09T23:10:36.624Z"
    }
   },
   "outputs": [],
   "source": [
    "# let's compute MSE for MA(1) model also\n",
    "mse_ma <- #your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:10:37.171001Z",
     "start_time": "2020-10-09T23:10:37.146Z"
    }
   },
   "outputs": [],
   "source": [
    "mse_mean;mse_ar;mse_ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:11:39.748066Z",
     "start_time": "2020-10-09T23:11:39.730Z"
    }
   },
   "outputs": [],
   "source": [
    "# computing squared forecasting errors\n",
    "L.ma <- #your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:11:40.258410Z",
     "start_time": "2020-10-09T23:11:40.237Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's compare the MA(1) model with the constant\n",
    "# We've already computed DM test by ourselves, so we can legitimately use written function\n",
    "dm.test(e1 = L.mean_model, e2 = L.ma, h = 1, power = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:11:43.025485Z",
     "start_time": "2020-10-09T23:11:43.000Z"
    }
   },
   "outputs": [],
   "source": [
    "# And for curiosity do DM test for AR(1) and MA(1) models\n",
    "dm.test(e1 = L.ar, e2 = L.ma, h = 1, power = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- What can you say?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's extend our testing to multiple models case\n",
    "- I think it is enough to start with something simple as three models\n",
    "- The main inspiration were taken from [here](https://cran.r-project.org/web/packages/multDM/index.html)\n",
    "- Do not forget that as `R` is open source and you can always see what is going on inside the package\n",
    "- The question is would you understand though, as in some cases authors are using, for example, `C++` inside some functions\n",
    "- Anyway, this is not the case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:11:51.602898Z",
     "start_time": "2020-10-09T23:11:51.581Z"
    }
   },
   "outputs": [],
   "source": [
    "# the length of our forecats is basically the number of out-of-sample observations\n",
    "T <- N_OOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:11:52.216608Z",
     "start_time": "2020-10-09T23:11:52.195Z"
    }
   },
   "outputs": [],
   "source": [
    "# We have already calculated all losses\n",
    "# We need to calculate differences\n",
    "# We have three models -> we need two difference series\n",
    "d_1 <- #difference between mean model and AR(1) model\n",
    "d_2 <- #difference between AR(1) model and MA(1) model\n",
    "d_multiple <- cbind(d_1, d_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:11:53.023609Z",
     "start_time": "2020-10-09T23:11:53.002Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's put them into one vector\n",
    "d_multiple.mean <- #mean of the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ok, next is calculating a consistent estimator of its asymptotic variance\n",
    "- As I wrote earlier, I will use [`multDM`](https://cran.r-project.org/web/packages/multDM/index.html) package code that implemented this procedure from \n",
    "- [R.S. Mariano and D. Preve (2012) Statistical tests for multiple forecast comparison, Journal of Econometrics 169, 123-130](https://www.researchgate.net/publication/230667169_Statistical_Tests_for_Multiple_Forecast_Comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:11:54.163308Z",
     "start_time": "2020-10-09T23:11:54.141Z"
    }
   },
   "outputs": [],
   "source": [
    "omega <- #consistent variance estimator for 1-step ahead forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:11:54.749094Z",
     "start_time": "2020-10-09T23:11:54.731Z"
    }
   },
   "outputs": [],
   "source": [
    "# Our statistic is then\n",
    "S <- #your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:11:55.257339Z",
     "start_time": "2020-10-09T23:11:55.234Z"
    }
   },
   "outputs": [],
   "source": [
    "# use pchisq() function in order to get p-value\n",
    "pchisq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:11:55.538220Z",
     "start_time": "2020-10-09T23:11:55.502Z"
    }
   },
   "outputs": [],
   "source": [
    "# checking ourselves\n",
    "library(multDM)\n",
    "MDM.test(realized = y_true, \n",
    "         evaluated = t(cbind(y_pred_mean, y_pred_ar, y_pred_ma)), \n",
    "         q = 0, \n",
    "         statistic = 'S', \n",
    "         loss.type = 'SE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giacomini and White test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Anyway, it is quite a good idea to use not just AR(1) or MA(1) models but, for example, ARMA(1, 1) model\n",
    "- Still, the question is how to compare predictions of, for example, AR(1) and ARMA(1, 1) models \n",
    "- I hope you understand why such question arises\n",
    "- [Giacomini and White (2006)](https://12f404d7-f421-6d2a-2b6f-c6eeccdc238a.filesusr.com/ugd/55ca8b_acdd79b07ce300e2160466839f5d0d45.pdf) might help us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Still, let's first get predictions from ARMA(1, 1) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:12:59.297354Z",
     "start_time": "2020-10-09T23:12:01.200Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_arma <- #initialiaze a vector\n",
    "\n",
    "for (i in 1:N_OOS){\n",
    "    y_train <- # keep your train data\n",
    "    arma <- #fit the model\n",
    "    y_pred_arma[i] <- #make a forecast\n",
    "}\n",
    "\n",
    "y_pred_arma <- as.xts(y_pred_arma, order.by = index(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:13:30.299748Z",
     "start_time": "2020-10-09T23:13:30.107Z"
    }
   },
   "outputs": [],
   "source": [
    "par(xpd = T)\n",
    "plot(x = cbind(y_true, y_pred_mean, y_pred_ar, y_pred_ma, y_pred_arma), \n",
    "     main = 'Returns and predictions', \n",
    "     y = index(y_true), \n",
    "     col = 1:5,\n",
    "     lwd = c(1, 2, 2, 2, 2))\n",
    "legend('bottomleft', \n",
    "       legend = c('Returns', 'Mean model predictions', 'AR(1) model predictions', 'MA(1) model predictions', 'ARMA(1, 1) model predictions'), \n",
    "       col = 1:5,\n",
    "       lty = c(1, 1, 1, 1),\n",
    "       inset = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:13:31.703033Z",
     "start_time": "2020-10-09T23:13:31.683Z"
    }
   },
   "outputs": [],
   "source": [
    "# let's compute MSE for MA(1) model also\n",
    "mse_arma <- #your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:13:32.232572Z",
     "start_time": "2020-10-09T23:13:32.205Z"
    }
   },
   "outputs": [],
   "source": [
    "mse_mean;mse_ar;mse_ma;mse_arma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:13:32.619544Z",
     "start_time": "2020-10-09T23:13:32.597Z"
    }
   },
   "outputs": [],
   "source": [
    "L.arma <- #calculate squared forecasting errors\n",
    "\n",
    "d_gw <- #calculate the difference series between ARMA(1, 1) model and AR(1) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As were written in the lecture notes, it is a common practice to say that $h^{*}_t$ is a unit vector and past forecast error\n",
    "- Please, be very careful with indices. It really does matter for this test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:13:34.309790Z",
     "start_time": "2020-10-09T23:13:34.290Z"
    }
   },
   "outputs": [],
   "source": [
    "TT <- T-1\n",
    "h <- #bing vector of ones of length (T-1) and difference series from 1 to (T-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:13:34.680087Z",
     "start_time": "2020-10-09T23:13:34.662Z"
    }
   },
   "outputs": [],
   "source": [
    "d_gw <- #re-write your difference series from 2 to T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:13:34.918196Z",
     "start_time": "2020-10-09T23:13:34.878Z"
    }
   },
   "outputs": [],
   "source": [
    "# As we have 1-step ahead forecast we can this\n",
    "\n",
    "hL <- matrix(0, nrow = nrow(h), ncol = ncol(h))\n",
    "\n",
    "for (i in 1:ncol(h)){\n",
    "    hL[, i] <- # multiply your h and new difference series. Be careful with xts. Better to convert to vectors and multiply them\n",
    "}\n",
    "\n",
    "omega_gw <- #calculate consistent variance estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:13:35.110604Z",
     "start_time": "2020-10-09T23:13:35.092Z"
    }
   },
   "outputs": [],
   "source": [
    "gw <- #use formula for the statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:13:35.809466Z",
     "start_time": "2020-10-09T23:13:35.788Z"
    }
   },
   "outputs": [],
   "source": [
    "gw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T23:13:36.644092Z",
     "start_time": "2020-10-09T23:13:36.620Z"
    }
   },
   "outputs": [],
   "source": [
    "#calculate p-value\n",
    "pchisq()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For those of you who know `MatLab` you can check my translation from `MatLab` to `R` by using the original code of the authors from [here](http://www.runmycode.org/companion/view/88)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "577px",
    "left": "1550px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
